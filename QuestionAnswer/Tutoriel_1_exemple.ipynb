{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutoriel 1 - Modèle Bag of Words (BOW) à l'aide d'NLTK et pandas"
   ],
   "metadata": {
    "id": "fWpHzhobWbDG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0. Téléchargement d'un livre éléctronique"
   ],
   "metadata": {
    "id": "EK8jLNxdd6-M"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from urllib import request\r\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\r\n",
    "response = request.urlopen(url)\r\n",
    "raw = response.read().decode('utf8')\r\n",
    "print(raw[:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The Project Gutenberg eBook of Crime and Punishment, by Fyodor Dostoevsky\n",
      "\n",
      "This eBook is for the \n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-yhXA_2WWf4",
    "outputId": "068f3d75-838d-4fab-e7a4-61e197bb47ec"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Tokenization de phrases et création d'un DataFrame Pandas\n",
    "\n",
    "On utilise le Sentence Tokenizer d'NLTK pour séparer le text brut en phrases. Chaque phrase ainsi obtenue correspond à une rangée du DataFrame.\n",
    "\n",
    "df.head() permet d'afficher les premières rangées (5 par défaut) d'un DataFrame."
   ],
   "metadata": {
    "id": "PqZCGqk7eAds"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\r\n",
    "from nltk.tokenize import sent_tokenize\r\n",
    "import nltk\r\n",
    "\r\n",
    "nltk.download(\"punkt\")\r\n",
    "\r\n",
    "df = pd.DataFrame({\"documents\": sent_tokenize(raw)})\r\n",
    "df.head(10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\FabriceNdui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           documents\n",
       "0  ﻿The Project Gutenberg eBook of Crime and Puni...\n",
       "1  You may copy it, give it away or re-use it und...\n",
       "2  If you are not located in the United States, y...\n",
       "3  Title: Crime and Punishment\\r\\n\\r\\nAuthor: Fyo...\n",
       "4                Dostoevsky was the son of a doctor.\n",
       "5  His parents were very hard-working\\r\\nand deep...\n",
       "6  The father and mother spent their evenings\\r\\n...\n",
       "7  Though always sickly and delicate Dostoevsky c...\n",
       "8  There he had\\r\\nalready begun his first work, ...\n",
       "9  The shy, unknown youth found himself\\r\\ninstan..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿The Project Gutenberg eBook of Crime and Puni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You may copy it, give it away or re-use it und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you are not located in the United States, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Title: Crime and Punishment\\r\\n\\r\\nAuthor: Fyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dostoevsky was the son of a doctor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>His parents were very hard-working\\r\\nand deep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The father and mother spent their evenings\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Though always sickly and delicate Dostoevsky c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>There he had\\r\\nalready begun his first work, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The shy, unknown youth found himself\\r\\ninstan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "Yt_i2so_ZSfo",
    "outputId": "8665f7dd-90a9-48f6-8c74-679c74bdf46c"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Tokenization de mots et fonction apply\n",
    "\n",
    "Les documents (phrases) sont séparés en token à l'aide de l'outil word_tokenize. Cette opération est vectorisée et appliquée à l'ensemble des lignes du DataFrame avec l'opération \"apply\".\n",
    "\n",
    "À noter que dans ce contexte, la valeur assignée à la colonne \"words\" d'une rangée correspond à celle retournée par la fonction word_tokenize si on lui passait la valeur \"documents\" de la même rangée."
   ],
   "metadata": {
    "id": "Gk0oGnMbeWfp"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from nltk.tokenize import word_tokenize\r\n",
    "\r\n",
    "df[\"words\"] = df[\"documents\"].apply(word_tokenize)\r\n",
    "print(df[\"words\"][0])\r\n",
    "print(type(df[\"words\"][0]))\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by', 'Fyodor', 'Dostoevsky', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.']\n",
      "<class 'list'>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           documents  \\\n",
       "0  ﻿The Project Gutenberg eBook of Crime and Puni...   \n",
       "1  You may copy it, give it away or re-use it und...   \n",
       "2  If you are not located in the United States, y...   \n",
       "3  Title: Crime and Punishment\\r\\n\\r\\nAuthor: Fyo...   \n",
       "4                Dostoevsky was the son of a doctor.   \n",
       "\n",
       "                                               words  \n",
       "0  [﻿The, Project, Gutenberg, eBook, of, Crime, a...  \n",
       "1  [You, may, copy, it, ,, give, it, away, or, re...  \n",
       "2  [If, you, are, not, located, in, the, United, ...  \n",
       "3  [Title, :, Crime, and, Punishment, Author, :, ...  \n",
       "4      [Dostoevsky, was, the, son, of, a, doctor, .]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿The Project Gutenberg eBook of Crime and Puni...</td>\n",
       "      <td>[﻿The, Project, Gutenberg, eBook, of, Crime, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You may copy it, give it away or re-use it und...</td>\n",
       "      <td>[You, may, copy, it, ,, give, it, away, or, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you are not located in the United States, y...</td>\n",
       "      <td>[If, you, are, not, located, in, the, United, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Title: Crime and Punishment\\r\\n\\r\\nAuthor: Fyo...</td>\n",
       "      <td>[Title, :, Crime, and, Punishment, Author, :, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dostoevsky was the son of a doctor.</td>\n",
       "      <td>[Dostoevsky, was, the, son, of, a, doctor, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "JTVNXW0_aRR1",
    "outputId": "d751ff22-0c9c-4e33-cd92-51213fa55d8f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Retrait des stopwords\n",
    "\n",
    "Une fonction lambda est appliquée sur la colonne \"words\" de chaque rangée avec apply. La fonction lambda permet de manipuler explicitement la valeur existante d'une rangée.\n",
    "\n",
    "La manipulation effectuée dans cet exemple est la création d'une liste de mots sans stopwords, en reprenant chaque élément de la colonne \"words\" et ne gardant ceux ne figurant pas dans la liste des stopwords d'NLTK.\n",
    "\n"
   ],
   "metadata": {
    "id": "G9Sz6rqHe5z3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\r\n",
    "from nltk.corpus import stopwords\r\n",
    "nltk.download(\"stopwords\")\r\n",
    "\r\n",
    "stop_words = set(stopwords.words(\"english\"))\r\n",
    "\r\n",
    "df[\"stopwords_removed\"] = df[\"words\"].apply(lambda words: [word for word in words if word not in stop_words])\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\FabriceNdui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           documents  \\\n",
       "0  ﻿The Project Gutenberg eBook of Crime and Puni...   \n",
       "1  You may copy it, give it away or re-use it und...   \n",
       "2  If you are not located in the United States, y...   \n",
       "3  Title: Crime and Punishment\\r\\n\\r\\nAuthor: Fyo...   \n",
       "4                Dostoevsky was the son of a doctor.   \n",
       "\n",
       "                                               words  \\\n",
       "0  [﻿The, Project, Gutenberg, eBook, of, Crime, a...   \n",
       "1  [You, may, copy, it, ,, give, it, away, or, re...   \n",
       "2  [If, you, are, not, located, in, the, United, ...   \n",
       "3  [Title, :, Crime, and, Punishment, Author, :, ...   \n",
       "4      [Dostoevsky, was, the, son, of, a, doctor, .]   \n",
       "\n",
       "                                   stopwords_removed  \n",
       "0  [﻿The, Project, Gutenberg, eBook, Crime, Punis...  \n",
       "1  [You, may, copy, ,, give, away, re-use, terms,...  \n",
       "2  [If, located, United, States, ,, check, laws, ...  \n",
       "3  [Title, :, Crime, Punishment, Author, :, Fyodo...  \n",
       "4                       [Dostoevsky, son, doctor, .]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>words</th>\n",
       "      <th>stopwords_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿The Project Gutenberg eBook of Crime and Puni...</td>\n",
       "      <td>[﻿The, Project, Gutenberg, eBook, of, Crime, a...</td>\n",
       "      <td>[﻿The, Project, Gutenberg, eBook, Crime, Punis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You may copy it, give it away or re-use it und...</td>\n",
       "      <td>[You, may, copy, it, ,, give, it, away, or, re...</td>\n",
       "      <td>[You, may, copy, ,, give, away, re-use, terms,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you are not located in the United States, y...</td>\n",
       "      <td>[If, you, are, not, located, in, the, United, ...</td>\n",
       "      <td>[If, located, United, States, ,, check, laws, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Title: Crime and Punishment\\r\\n\\r\\nAuthor: Fyo...</td>\n",
       "      <td>[Title, :, Crime, and, Punishment, Author, :, ...</td>\n",
       "      <td>[Title, :, Crime, Punishment, Author, :, Fyodo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dostoevsky was the son of a doctor.</td>\n",
       "      <td>[Dostoevsky, was, the, son, of, a, doctor, .]</td>\n",
       "      <td>[Dostoevsky, son, doctor, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "IVrRmjamaXcf",
    "outputId": "e1b3fc04-9026-4279-8dc7-0262732e1d4e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Stemming et Lemmatization\n",
    "\n",
    "Utilisation des librairies de NLTK pour stemmer ou lemmatizer les listes de mots de chaque phrase."
   ],
   "metadata": {
    "id": "YWTb0tGdf593"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from nltk.stem import PorterStemmer\r\n",
    "ps = PorterStemmer()\r\n",
    "\r\n",
    "df[\"porter_stemmed\"] = df[\"stopwords_removed\"].apply(lambda words: [ps.stem(word) for word in words])\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           documents  \\\n",
       "0  ﻿The Project Gutenberg eBook of Crime and Puni...   \n",
       "1  You may copy it, give it away or re-use it und...   \n",
       "2  If you are not located in the United States, y...   \n",
       "3  Title: Crime and Punishment\\r\\n\\r\\nAuthor: Fyo...   \n",
       "4                Dostoevsky was the son of a doctor.   \n",
       "\n",
       "                                               words  \\\n",
       "0  [﻿The, Project, Gutenberg, eBook, of, Crime, a...   \n",
       "1  [You, may, copy, it, ,, give, it, away, or, re...   \n",
       "2  [If, you, are, not, located, in, the, United, ...   \n",
       "3  [Title, :, Crime, and, Punishment, Author, :, ...   \n",
       "4      [Dostoevsky, was, the, son, of, a, doctor, .]   \n",
       "\n",
       "                                   stopwords_removed  \\\n",
       "0  [﻿The, Project, Gutenberg, eBook, Crime, Punis...   \n",
       "1  [You, may, copy, ,, give, away, re-use, terms,...   \n",
       "2  [If, located, United, States, ,, check, laws, ...   \n",
       "3  [Title, :, Crime, Punishment, Author, :, Fyodo...   \n",
       "4                       [Dostoevsky, son, doctor, .]   \n",
       "\n",
       "                                      porter_stemmed  \n",
       "0  [﻿the, project, gutenberg, ebook, crime, punis...  \n",
       "1  [you, may, copi, ,, give, away, re-us, term, p...  \n",
       "2  [If, locat, unit, state, ,, check, law, countr...  \n",
       "3  [titl, :, crime, punish, author, :, fyodor, do...  \n",
       "4                       [dostoevski, son, doctor, .]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>words</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>porter_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿The Project Gutenberg eBook of Crime and Puni...</td>\n",
       "      <td>[﻿The, Project, Gutenberg, eBook, of, Crime, a...</td>\n",
       "      <td>[﻿The, Project, Gutenberg, eBook, Crime, Punis...</td>\n",
       "      <td>[﻿the, project, gutenberg, ebook, crime, punis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You may copy it, give it away or re-use it und...</td>\n",
       "      <td>[You, may, copy, it, ,, give, it, away, or, re...</td>\n",
       "      <td>[You, may, copy, ,, give, away, re-use, terms,...</td>\n",
       "      <td>[you, may, copi, ,, give, away, re-us, term, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you are not located in the United States, y...</td>\n",
       "      <td>[If, you, are, not, located, in, the, United, ...</td>\n",
       "      <td>[If, located, United, States, ,, check, laws, ...</td>\n",
       "      <td>[If, locat, unit, state, ,, check, law, countr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Title: Crime and Punishment\\r\\n\\r\\nAuthor: Fyo...</td>\n",
       "      <td>[Title, :, Crime, and, Punishment, Author, :, ...</td>\n",
       "      <td>[Title, :, Crime, Punishment, Author, :, Fyodo...</td>\n",
       "      <td>[titl, :, crime, punish, author, :, fyodor, do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dostoevsky was the son of a doctor.</td>\n",
       "      <td>[Dostoevsky, was, the, son, of, a, doctor, .]</td>\n",
       "      <td>[Dostoevsky, son, doctor, .]</td>\n",
       "      <td>[dostoevski, son, doctor, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {
    "id": "FyhQrUDMcV_I"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\r\n",
    "nltk.download(\"wordnet\")\r\n",
    "lem = WordNetLemmatizer()\r\n",
    "\r\n",
    "df[\"word_net_lemm\"] = df[\"stopwords_removed\"].apply(lambda words: [lem.lemmatize(word) for word in words])\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\FabriceNdui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           documents  \\\n",
       "0  ﻿The Project Gutenberg eBook of Crime and Puni...   \n",
       "1  You may copy it, give it away or re-use it und...   \n",
       "2  If you are not located in the United States, y...   \n",
       "3  Title: Crime and Punishment\\r\\n\\r\\nAuthor: Fyo...   \n",
       "4                Dostoevsky was the son of a doctor.   \n",
       "\n",
       "                                               words  \\\n",
       "0  [﻿The, Project, Gutenberg, eBook, of, Crime, a...   \n",
       "1  [You, may, copy, it, ,, give, it, away, or, re...   \n",
       "2  [If, you, are, not, located, in, the, United, ...   \n",
       "3  [Title, :, Crime, and, Punishment, Author, :, ...   \n",
       "4      [Dostoevsky, was, the, son, of, a, doctor, .]   \n",
       "\n",
       "                                   stopwords_removed  \\\n",
       "0  [﻿The, Project, Gutenberg, eBook, Crime, Punis...   \n",
       "1  [You, may, copy, ,, give, away, re-use, terms,...   \n",
       "2  [If, located, United, States, ,, check, laws, ...   \n",
       "3  [Title, :, Crime, Punishment, Author, :, Fyodo...   \n",
       "4                       [Dostoevsky, son, doctor, .]   \n",
       "\n",
       "                                      porter_stemmed  \\\n",
       "0  [﻿the, project, gutenberg, ebook, crime, punis...   \n",
       "1  [you, may, copi, ,, give, away, re-us, term, p...   \n",
       "2  [If, locat, unit, state, ,, check, law, countr...   \n",
       "3  [titl, :, crime, punish, author, :, fyodor, do...   \n",
       "4                       [dostoevski, son, doctor, .]   \n",
       "\n",
       "                                       word_net_lemm  \n",
       "0  [﻿The, Project, Gutenberg, eBook, Crime, Punis...  \n",
       "1  [You, may, copy, ,, give, away, re-use, term, ...  \n",
       "2  [If, located, United, States, ,, check, law, c...  \n",
       "3  [Title, :, Crime, Punishment, Author, :, Fyodo...  \n",
       "4                       [Dostoevsky, son, doctor, .]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>words</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>porter_stemmed</th>\n",
       "      <th>word_net_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿The Project Gutenberg eBook of Crime and Puni...</td>\n",
       "      <td>[﻿The, Project, Gutenberg, eBook, of, Crime, a...</td>\n",
       "      <td>[﻿The, Project, Gutenberg, eBook, Crime, Punis...</td>\n",
       "      <td>[﻿the, project, gutenberg, ebook, crime, punis...</td>\n",
       "      <td>[﻿The, Project, Gutenberg, eBook, Crime, Punis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You may copy it, give it away or re-use it und...</td>\n",
       "      <td>[You, may, copy, it, ,, give, it, away, or, re...</td>\n",
       "      <td>[You, may, copy, ,, give, away, re-use, terms,...</td>\n",
       "      <td>[you, may, copi, ,, give, away, re-us, term, p...</td>\n",
       "      <td>[You, may, copy, ,, give, away, re-use, term, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you are not located in the United States, y...</td>\n",
       "      <td>[If, you, are, not, located, in, the, United, ...</td>\n",
       "      <td>[If, located, United, States, ,, check, laws, ...</td>\n",
       "      <td>[If, locat, unit, state, ,, check, law, countr...</td>\n",
       "      <td>[If, located, United, States, ,, check, law, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Title: Crime and Punishment\\r\\n\\r\\nAuthor: Fyo...</td>\n",
       "      <td>[Title, :, Crime, and, Punishment, Author, :, ...</td>\n",
       "      <td>[Title, :, Crime, Punishment, Author, :, Fyodo...</td>\n",
       "      <td>[titl, :, crime, punish, author, :, fyodor, do...</td>\n",
       "      <td>[Title, :, Crime, Punishment, Author, :, Fyodo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dostoevsky was the son of a doctor.</td>\n",
       "      <td>[Dostoevsky, was, the, son, of, a, doctor, .]</td>\n",
       "      <td>[Dostoevsky, son, doctor, .]</td>\n",
       "      <td>[dostoevski, son, doctor, .]</td>\n",
       "      <td>[Dostoevsky, son, doctor, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "melLmO4sc7HA",
    "outputId": "3b30ed49-c4a8-4844-ab41-d9c5eed7efac"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Modèle Bag of Words\n",
    "\n",
    "Calcul de la fréquence des tokens dans le corpus, dont on garde les N (200 dans l'exemple) token les plus fréquents.\n",
    "\n",
    "Les phrases sont représentées par un vecteur de taille N: à chaque indice, 1 indique que ce Nième mot le plus fréquent est dans ladite phrase, 0 indique qu'il est absent de la phrase.\n",
    "\n",
    "Notez l'utilisation de la fonction \"value_counts\" sur une série Pandas; celle-ci retourne un décompte des valeurs les plus fréquentes d'une colonne."
   ],
   "metadata": {
    "id": "8QF5bnC-kU7K"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# décompte de tous les tokens dans le corpus entier\r\n",
    "vocab_words = pd.Series(word_tokenize(raw))\r\n",
    "vocab_words = [word for word in vocab_words if word not in stop_words]\r\n",
    "vocab_words = [lem.lemmatize(word) for word in vocab_words]\r\n",
    "\r\n",
    "# 200 mots les plus fréquents\r\n",
    "token_frequencies = pd.Series(vocab_words).value_counts().head(200).to_dict()\r\n",
    "token_frequencies"
   ],
   "outputs": [],
   "metadata": {
    "id": "eP5hHCxllayn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# 1 si le token parmi les plus fréquents est dans la phrase, 0 sinon\r\n",
    "def sentence_vector(sentence, token_frequencies):\r\n",
    "  return [1 if token in sentence else 0 for token in token_frequencies.keys()]"
   ],
   "outputs": [],
   "metadata": {
    "id": "LyGrdWiIl2rV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df[\"BOWrepresentation\"] = df.word_net_lemm.apply(lambda x: sentence_vector(x, token_frequencies))\r\n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "_T2AO70vj1v3",
    "outputId": "4195afa9-4e7c-4a0b-f9b4-271e7e0e0194"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Représentation des BOW en matrice numpy"
   ],
   "metadata": {
    "id": "PN35-xNPoIv6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "np.asarray(list(df.BOWrepresentation.values))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8Hf4HFRdvrY",
    "outputId": "59cb0181-94fd-4959-be69-714904c2d155"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6. Modèle TF-IDF avec sklearn\n"
   ],
   "metadata": {
    "id": "H-zqDC891_bF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "\r\n",
    "vectorizer = TfidfVectorizer()\r\n",
    "\r\n",
    "df[\"joined_lemmas\"] = df.word_net_lemm.apply(lambda x: \" \".join(x))\r\n",
    "\r\n",
    "tfidf = vectorizer.fit_transform(df[\"joined_lemmas\"].values)\r\n",
    "feature_names = vectorizer.get_feature_names()\r\n",
    "tfidf = tfidf.toarray()\r\n",
    "tfidf"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QBsfkuNe2Ee7",
    "outputId": "f0718c1a-626c-4c0b-81e7-b3f0e9237878"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. Distance entre deux représentations de documents\n",
    "\n",
    "La librairie scipy offre des outils pour les calculs de distance entre vecteurs unidimensionnels. Par exemple, voici comment calculer la distance cosinus entre les représentations TF-IDF des deux premières phrases du livre:"
   ],
   "metadata": {
    "id": "uT-JR8f4fHsb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "cosine(tfidf[0], tfidf[1])"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NQTQp8I3fkWg",
    "outputId": "4dc0f664-bf1d-4be7-8873-d7715e188f2c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "id": "GfcyvqbVfFYz"
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "exemples_tutoriel_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}