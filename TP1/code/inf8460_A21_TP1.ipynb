{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## <center> École Polytechnique de Montréal <br> Département Génie Informatique et Génie Logiciel <br>  INF8460 – Traitement automatique de la langue naturelle <br> </center>\n",
    "## <center> TP1 INF8460 <br>  Automne 2021 </center>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. DESCRIPTION\n",
    "Dans ce TP, l’idée est d’effectuer de la recherche de passages de texte dans un corpus à partir d’une question en langue naturelle. Les questions et passages sont en anglais.\n",
    "\n",
    "Voici un exemple : <br>\n",
    "__Entrée : Question :__ What causes precipitation to fall?  \n",
    "\n",
    "__Solution - Trouver un passage qui contient la réponse à la question :__ In meteorology, precipitation is any product of the condensation of atmospheric water vapor that falls under <mark> __gravity__ </mark>. The main forms of precipitation include drizzle, rain, sleet, snow, graupel and hail... Precipitation forms as smaller droplets coalesce via collision with other rain drops or ice crystals within a cloud. Short, intense periods of rain in scattered locations are called “showers”. \n",
    "\n",
    "Ici la réponse est en gras dans le texte."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. LIBRARIES PERMISES\n",
    "- Jupyter notebook\n",
    "- NLTK\n",
    "- Numpy \n",
    "- Pandas\n",
    "- Sklearn\n",
    "- Pour toute autre librairie, demandez à votre chargé de laboratoire\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. INFRASTRUCTURE\n",
    "\n",
    "- Vous avez accès aux GPU du local L-4818. Dans ce cas, vous devez utiliser le dossier temp (voir le tutoriel VirtualEnv.pdf)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. DESCRIPTION DES DONNEES\n",
    "\n",
    "Dans ce projet, vous utiliserez le jeu de données dans le répertoire _data_. Il est décomposé en données d’entrainement (train), de validation (dev) et de test (test). <br>\n",
    "\n",
    "Nous ne mettrons à votre disposition que les données d’entrainement et de validation. Les données de test ne contiennent pas le paragraphe de réponse et doivent être complétées avec les résultats de votre système.\n",
    "Nous vous fournissons un ensemble de données qui comprend un corpus (_corpus.csv_) qui contient tous les passages et leurs identificateurs (ID) et un jeu de données qui associe une question, un passage, et une réponse qui est directement extraite du passage. Notez que certains passages contiennent des balises HTML et qu’il vous faudra procéder à un prétraitement de ces passages pour les enlever. <br>\n",
    "Ce jeu de données est composé de trois sous-ensembles : \n",
    "- _Train_ : ensemble d’entraînement de la forme <QuestionID, QuestionText, PassageID, Réponse>. Le but est donc d’entrainer votre modèle à retrouver le passage qui contient la réponse à la question.\n",
    "- _Validation_ : De la même forme que le Train, il vous permet de valider votre entraînement et de tester les performances de certains modules.  \n",
    "- _Test_ : Un ensemble secret qui est utilisé pour évaluer votre système complet. Il est de la forme <QuestionID, Question>. Votre système doit trouver dans le corpus __corpus.csv__ le ou les passages les plus pertinents.\n",
    "\n",
    "Notez qu’il est possible de répondre aux requis du TP sans utiliser la réponse à la question. C’est à vous de choisir si vous utilisez la réponse ou non. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. ETAPES DU TP \n",
    "A partir du notebook _inf8460_A21_TP1_ qui est distribué, vous devez réaliser les étapes suivantes. (Noter que les cellules dans le squelette sont là à titre informatif - il est fort probable que vous rajoutiez des sections au fur et à mesure de votre TP)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ci-dessous définir la constante _PATH_ qui doit être utilisée par votre code pour accéder aux fichiers. Il est attendu que pour la correction, le chargé de lab n'ait qu'à changer la valeur de _PATH_ pour le répertoire où se trouver les fichiers de datasets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\"\"\" # For ubuntu\r\n",
    "import sys\r\n",
    "!{sys.executable} -m pip install pandas\r\n",
    "!{sys.executable} -m pip install nltk\r\n",
    "!{sys.executable} -m pip install sklearn\r\n",
    "!{sys.executable} -m pip install numpy\r\n",
    "import ssl\r\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\r\n",
    "\"\"\"\r\n",
    "import nltk\r\n",
    "nltk.download('punkt')\r\n",
    "nltk.download(\"stopwords\")\r\n",
    "nltk.download(\"wordnet\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\FabriceNdui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\FabriceNdui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\FabriceNdui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "PATH = \"data/\""
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "from nltk.stem import PorterStemmer\r\n",
    "import pandas as pd\r\n",
    "from nltk.tokenize import sent_tokenize\r\n",
    "from nltk.corpus import stopwords\r\n",
    "import numpy as np\r\n",
    "import nltk\r\n",
    "\r\n",
    "nltk.download(\"stopwords\")\r\n",
    "nltk.download(\"wordnet\")\r\n",
    "lem = WordNetLemmatizer()\r\n",
    "ps = PorterStemmer()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\FabriceNdui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\FabriceNdui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1. Pré-traitement (12 points)\n",
    "Les passages et questions de votre ensemble de données doivent d’abord être représentés et indexés pour ensuite pouvoir effectuer une recherche de passage pour répondre à une question. On vous demande donc d’implémenter une étape de pré-traitement des données.\n",
    "1) (_6 points_) Complétez les fonctions retournant les informations suivantes (une fonction par information, chaque fonction prenant en argument le corpus (passages, questions) composé d'une liste de phrases segmentées en jetons/tokens) :\n",
    "    1. Le nombre total de jetons (mots non distincts)\n",
    "    2. Le nombre total de mots distincts (les types qui constituent le vocabulaire)\n",
    "    3. Les N mots les plus fréquents du vocabulaire (N est un paramètre avec une valeur par défaut de 10) ainsi que leur fréquence\n",
    "    4. Le ratio jeton/type\n",
    "    5. Le nombre total de lemmes distincts\n",
    "    6. Le nombre total de racines (stems) distinctes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def total_non_distinct(corpus):\r\n",
    "    total = 0\r\n",
    "    for _i, paragraph in corpus.items():\r\n",
    "        total += len(paragraph)\r\n",
    "    return total\r\n",
    "    \r\n",
    "def total_distinct(corpus):\r\n",
    "    words = set()\r\n",
    "    for _i, paragraph in corpus.items():\r\n",
    "        for word in paragraph:\r\n",
    "            words.add(word)\r\n",
    "    return len(words)\r\n",
    "\r\n",
    "def most_frequent(corpus, n = 10):\r\n",
    "    words = {}\r\n",
    "    for _i, paragraph in corpus.items():\r\n",
    "        for word in paragraph:\r\n",
    "            if word in words:\r\n",
    "                words[word] += 1\r\n",
    "            else:\r\n",
    "                words[word] = 1\r\n",
    "    return list(sorted(words.items(), key=lambda temp: temp[1], reverse=True))[:n]\r\n",
    "    \r\n",
    "def ratio_jeton_type(corpus):\r\n",
    "    return total_non_distinct(corpus)/total_distinct(corpus)\r\n",
    "\r\n",
    "def total_lemme_distinct(corpus):\r\n",
    "    lemmed = corpus.apply(lambda words: [lem.lemmatize(word) for word in words])\r\n",
    "    return total_distinct(lemmed)\r\n",
    "    \r\n",
    "def total_stems_distinct(corpus):\r\n",
    "    stem = corpus.apply(lambda words: [ps.stem(word) for word in words])\r\n",
    "    return total_distinct(stem)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. (_1 point_) Ecrivez une fonction explore_corpus() qui fait appel à toutes les fonctions en 1) et imprime leur résultat.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def explore_corpus(corpus):\r\n",
    "    print(\"nombre total de jetons: \",total_non_distinct(corpus))\r\n",
    "    print(\"Nombre total de mots distincts: \", total_distinct(corpus))\r\n",
    "    print(\"Nombre total de mots distincts: \",most_frequent(corpus))\r\n",
    "    print(\"Ratio jeton/type: \",ratio_jeton_type(corpus))\r\n",
    "    print(\"Nombre total lemmes distincts: \",total_lemme_distinct(corpus))\r\n",
    "    print(\"Nombre total de racines distincts: \",total_stems_distinct(corpus))\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. (_5 points_) Pour la suite du TP, vous devez effectuer le pré-traitement du corpus (questions, passages) en convertissant le texte en minuscules, en segmentant le texte, en supprimant les mots outils et en lemmatisant le texte. Chaque opération doit avoir sa fonction python si elle n’est pas déjà implantée dans la question 1) précédente."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "corpus = pd.read_csv(PATH+\"corpus.csv\", usecols = [1])\r\n",
    "questions = pd.read_csv(PATH+\"train_ids.csv\", usecols = [2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "corpus.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           paragraph\n",
       "0  The Normans (Norman: Nourmands; French: Norman...\n",
       "1  The Norman dynasty had a major political, cult...\n",
       "2  The English name \"Normans\" comes from the Fren...\n",
       "3  In the course of the 10th century, the initial...\n",
       "4  Before Rollo's arrival, its populations did no..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Norman dynasty had a major political, cult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The English name \"Normans\" comes from the Fren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the course of the 10th century, the initial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Before Rollo's arrival, its populations did no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "questions.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            question\n",
       "0  Who leaders the sub-divisions of offices or di...\n",
       "1  Besides using 3kV DC what other power type is ...\n",
       "2  How many other cities had populations larger t...\n",
       "3     Did von Neumann rule hidden variable theories?\n",
       "4  What is the name of the book that has the laws..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who leaders the sub-divisions of offices or di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Besides using 3kV DC what other power type is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many other cities had populations larger t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did von Neumann rule hidden variable theories?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the name of the book that has the laws...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "paragraphs = corpus[\"paragraph\"].apply(word_tokenize)\r\n",
    "paragraphs.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    [The, Normans, (, Norman, :, Nourmands, ;, Fre...\n",
       "1    [The, Norman, dynasty, had, a, major, politica...\n",
       "2    [The, English, name, ``, Normans, '', comes, f...\n",
       "3    [In, the, course, of, the, 10th, century, ,, t...\n",
       "4    [Before, Rollo, 's, arrival, ,, its, populatio...\n",
       "Name: paragraph, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "explore_corpus(paragraphs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nombre total de jetons:  11922724\n",
      "Nombre total de mots distincts:  213164\n",
      "Nombre total de mots distincts:  [('the', 595302), (',', 571498), ('>', 410243), ('<', 410182), ('.', 383281), ('of', 307955), ('and', 270716), ('in', 219592), ('to', 174688), ('a', 166063)]\n",
      "Ratio jeton/type:  55.932164905894055\n",
      "Nombre total lemmes distincts:  203790\n",
      "Nombre total de racines distincts:  155592\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def transform_min(corpus):\r\n",
    "    return corpus.str.lower()\r\n",
    "\r\n",
    "def tokenize(corpus):\r\n",
    "    return corpus.apply(word_tokenize)\r\n",
    "\r\n",
    "def removeStopWords(corpus):\r\n",
    "    stop_words = set(stopwords.words(\"english\"))\r\n",
    "    return corpus.apply(lambda words: [word for word in words if word not in stop_words])\r\n",
    "\r\n",
    "def lemmatize(corpus):\r\n",
    "    lem = WordNetLemmatizer()\r\n",
    "    return corpus.apply(lambda words: [lem.lemmatize(word) for word in words])\r\n",
    "\r\n",
    "def clean_data(corpus):\r\n",
    "    corpus = transform_min(corpus)\r\n",
    "    corpus = tokenize(corpus)\r\n",
    "    corpus = removeStopWords(corpus)\r\n",
    "    corpus = lemmatize(corpus)\r\n",
    "    return corpus"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "corpus = clean_data(corpus[\"paragraph\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "questions = clean_data(questions[\"question\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "corpus.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    [norman, (, norman, :, nourmands, ;, french, :...\n",
       "1    [norman, dynasty, major, political, ,, cultura...\n",
       "2    [english, name, ``, norman, '', come, french, ...\n",
       "3    [course, 10th, century, ,, initially, destruct...\n",
       "4    [rollo, 's, arrival, ,, population, differ, pi...\n",
       "Name: paragraph, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2. Représentation de questions et de passages (14 points)\n",
    "\n",
    "1. (_10 points_) En utilisant sklearn et à partir de votre corpus pré-traité, vous devez implanter un modèle M1 qui est de représenter chaque passage et question avec votre vocabulaire, en utilisant un modèle sac de mots des n-grammes (n=1) qu’ils contiennent et en pondérant ces éléments avec TF-IDF. Notez que les questions doivent aussi être inclues dans la construction du vocabulaire."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "paragraphs_t = corpus.apply(lambda x: \" \".join(x))\r\n",
    "questions_t = questions.apply(lambda x: \" \".join(x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "questions_paragraph = pd.concat([paragraphs_t, questions_t], axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "def tfidf_model(model=1):\r\n",
    "  vectorizer1 = TfidfVectorizer(ngram_range=(1, model))\r\n",
    "  tfidf = vectorizer1.fit(questions_paragraph.values)\r\n",
    "  return vectorizer1.transform(questions_t), vectorizer1.transform(paragraphs_t)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "tfidf_questions1, tfidf_paragraphs1 = tfidf_model()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. (_4 points_) Expérimentez maintenant avec un modèle n-gramme (n=1,2) mélangeant les unigrammes et les bigrammes et pondéré avec TF-IDF."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "tfidf_questions2, tfidf_paragraphs2 = tfidf_model(model=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pour M1 et M2, assurez-vous de réutiliser la même fonction avec comme paramètre les n-grammes à considérer."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.3. Ordonnancement des passages (10 points)\n",
    "Maintenant que vous avez une représentation de vos passages et questions, il faut être capable de déterminer quel passage sera le plus pertinent pour la question posée. Il vous faut donc retrouver un top-N (N=1,5,10 … ) de passages utiles pour répondre à la question. Ces passages devront être ordonnés du plus pertinent au moins pertinent. Idéalement le passage à la position 1 sera celui qui contient la réponse à la question.\n",
    "<br>\n",
    "<br>\n",
    "Vous devez écrire des fonctions pour évaluer la similarité entre la représentation de la question et celle de chaque passage et retourner les N passage les plus similaires où N est un paramètre. \n",
    "1. (_5 points_) En utilisant la distance euclidienne\n",
    "2. (_5 points_) En utilisant la distance cosinus\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "def euclidean_distances_per_question(question, n=1):\r\n",
    "  tfidfs = euclidean_distances(question, tfidf_paragraphs1)[0]\r\n",
    "  return np.argsort(tfidfs)[:n]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "def cosinus_distances_per_question(question, n=1):\r\n",
    "  tfidfs = cosine_distances(question, tfidf_paragraphs1)[0]\r\n",
    "  return np.argsort(tfidfs)[:n]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "euclidean_distances_per_question(tfidf_questions1[9,], 30)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 6642, 83055, 81077, 27041, 17797,  5771, 74938, 23824, 33772,\n",
       "       81269,  7544, 81733,  6648, 65286, 27925, 50161, 50907, 39294,\n",
       "       54172, 53859, 18876, 53154, 54844, 18538, 28877, 16814, 44444,\n",
       "       59456, 33732, 80360], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "cosinus_distances_per_question(tfidf_questions1[9,], 30)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 6642, 83055, 81077, 27041, 17797,  5771, 74938, 23824, 33772,\n",
       "       81269,  7544, 81733,  6648, 65286, 27925, 50161, 50907, 39294,\n",
       "       54172, 53859, 18876, 53154, 54844, 18538, 28877, 16814, 44444,\n",
       "       59456, 33732, 80360], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.4. Évaluation (15 points)\n",
    "En utilisant votre ensemble de validation : <br>\n",
    "1. (_5 points_) Vous devez calculer la précision top-N (N=1,5,10, 50) de votre modèle M1 et M2 avec la distance euclidienne et cosinus et les afficher. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "eval = pd.read_csv(PATH+\"val_ids.csv\", usecols = [1, 3])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def precision(data):\r\n",
    "  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "eval.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  paragraph_id\n",
       "0   0       17134.0\n",
       "1   2        6902.0\n",
       "2   3        2178.0\n",
       "3   5       10150.0\n",
       "4   6        1928.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraph_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6902.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>10150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1928.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. (_5 points_) Pour chacun de ces modèles, générez une courbe de performance faisant varier le N (N=1, 5, 10, 50)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. (_5 points_) A cette étape, vous devez produire un fichier _passage_submission_M1.csv_ et _passage_submission_M2.csv_ qui contient pour toutes les questions de l’ensemble de test le top-N des passages retournés par votre modèle M1 et M2 pour y répondre. C’est à vous de déterminer si vous utiliserez la distance euclidienne ou cosinus basé sur vos résultats d’évaluation sur l’ensemble de validation en 1) et 2). Le fichier doit respecter le format suivant pour chaque top_N(N=1,5,10,50) :  <QuestionID, PassageID1 ;… ;PassageIDN>. Le format est démontré dans _sample_passage_submission.csv_."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.5. Le plus (24 points)\n",
    "\n",
    "1. (_21 points_) Vous devez proposer un modèle M3 différent (basé sur l’apprentissage machine par exemple) afin de déterminer un score de pertinence d’un passage pour une question donnée et ordonner les passages. \n",
    "    - Faites une petite recherche sur l’état de l’art en consultant https://nlp.stanford.edu/IR-book/information-retrieval-book.html\n",
    "    - Vous êtes libres de proposer une autre métrique de poids, ou une autre façon d’ordonner les passages (exemple : méthodes de type _learning to rank_) et de partir de votre corpus initial ou de votre ordonnancement en M1/M2 (choisissez le meilleur) et de réordonnancer les passages obtenus par votre premier modèle.\n",
    "    - Expliquez votre modèle et son intérêt dans votre notebook. Le nombre de points obtenus dépendra de l’effort mis dans cette partie."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. (_2  point_) Vous devez ensuite afficher l’évaluation de votre modèle M3 tel que décrit dans la section 5.4 Evaluation en utilisant les mêmes fonctions. Notamment, vous devez comparer les performances de vos modèles M1, M2 et M3 sur l’ensemble de validation avec une courbe de performance faisant varier le N (N=1, 5, 10, …)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. (_1 point_) En utilisant votre modèle M3, vous devez produire un fichier passage_submission_M3.csv qui contient pour toutes les questions de l’ensemble de test le top-N des passages retournés par votre système pour y répondre. Le fichier doit respecter le format suivant pour chaque top_N (N=1,5,10,50) :  <QuestionID, PassageID1…PassageIDN>. _Le format est démontré dans sample_passage_submission.csv_"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LIVRABLES\n",
    "Vous devez remettre sur Moodle:\n",
    "1. _Le code_ : Un Jupyter notebook en Python qui contient le code implanté avec les librairies permises. Le code doit être exécutable sans erreur et accompagné des commentaires appropriés dans le notebook de manière à expliquer les différentes fonctions et étapes dans votre projet. Nous nous réservons le droit de demander une démonstration ou la preuve que vous avez effectué vous-mêmes les expériences décrites. _Attention, en aucun cas votre code ne doit avoir été copié d’une quelconque source_. Les critères de qualité tels que la lisibilité du code et des commentaires sont importants. Tout votre code et vos résultats doivent être exécutables et reproductibles ; \n",
    "2. Un fichier _requirements.txt_ doit indiquer toutes les librairies / données nécessaires ;\n",
    "3. Un lien _GoogleDrive_ ou similaire vers les modèles nécessaires pour exécuter votre notebook si approprié ;\n",
    "4. Les fichiers de soumission de données de test _passage_submission_M1.csv_ et _passage_submission_M2.csv_\n",
    "5. Un document _contributions.txt_ : Décrivez brièvement la contribution de chaque membre de l’équipe. Tous les membres sont censés contribuer au développement. Bien que chaque membre puisse effectuer différentes tâches, vous devez vous efforcer d’obtenir une répartition égale du travail. En particulier, tous les membres du projet devraient participer à la conception du TP et participer activement à la réflexion et à l’implémentation du code.\n",
    "\n",
    "## EVALUATION \n",
    "Votre TP sera évalué selon les critères suivants :\n",
    "1. Exécution correcte du code\n",
    "2. Performance correcte des modèles\n",
    "3. Organisation du notebook\n",
    "4. Qualité du code (noms significatifs, structure, performance, gestion d’exception, etc.)\n",
    "5. Commentaires clairs et informatifs\n",
    "\n",
    "## CODE D’HONNEUR\n",
    "- Règle 1:  Le plagiat de code est bien évidemment interdit.\n",
    "- Règle 2: Vous êtes libres de discuter des idées et des détails de mise en œuvre avec d'autres équipes. Cependant, vous ne pouvez en aucun cas consulter le code d'une autre équipe INF8460, ou incorporer leur code dans votre TP.\n",
    "- Règle 3:  Vous ne pouvez pas partager votre code publiquement (par exemple, dans un dépôt GitHub public) tant que le cours n'est pas fini.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}