{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKOTlwcmxmej"
   },
   "source": [
    "# Reconnaissance d'entités nommées avec BERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqRXcKmU54ZX"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DEfSbAA4QHas",
    "outputId": "c02c2d77-e65d-4f70-ea13-5c1ba4a6d39f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4180/1845739142.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Get the GPU device name.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYsV4H8fCpZ-",
    "outputId": "b9e5caed-e028-40ae-a282-300b9c576bdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NmMdkZO8R6q",
    "outputId": "f4f91edc-8707-4efb-e7f6-1eb47728bba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (4.12.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from transformers) (0.1.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: six in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\soule\\.conda\\envs\\inf8460\\lib\\site-packages (from sacremoses->transformers) (8.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guw6ZNtaswKc"
   },
   "source": [
    "## Jeu de données\n",
    "https://groups.csail.mit.edu/sls/downloads/restaurant/\n",
    "\n",
    "Reconnaissance des types suivants:\n",
    "\n",
    "- Amenity\n",
    "- Cuisine\n",
    "- Dish\n",
    "- Hours\n",
    "- Location\n",
    "- Price\n",
    "- Rating\n",
    "- Restaurant_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5m6AnuFv0QXQ",
    "outputId": "f9e43110-6235-4ede-c8a3-62685563f7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Using cached wget-3.2-py3-none-any.whl\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "rDW8NXhtoqyT",
    "outputId": "fb5d3630-a243-4a4b-d77d-7d9367699ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n",
      "100% [............................................................................] 155722 / 155722"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./restauranttest.bio'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "print('Downloading dataset...')\n",
    "\n",
    "# The URL for the *training* examples.\n",
    "url = 'https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttrain.bio'\n",
    "\n",
    "# Download the file (if we haven't already)\n",
    "#if not os.path.exists('./restauranttrain.bio'):\n",
    "wget.download(url, './restauranttrain.bio')\n",
    "\n",
    "# The URL for the *test* examples.\n",
    "url = 'https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttest.bio'\n",
    "\n",
    "# Download the file (if we haven't already)\n",
    "#if not os.path.exists('./restauranttest.bio'):\n",
    "wget.download(url, './restauranttest.bio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4dNMdoF54Zf"
   },
   "source": [
    "Nous allons séparer les données en :\n",
    "- **sentences** : listes des phrases segmentées\n",
    "- **labels** : liste des IOB correspondants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CkAWuZTalRjy"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# List of all sentences in the dataset.\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "# Lists to store the current sentence.\n",
    "tokens = []\n",
    "token_labels = []\n",
    "\n",
    "# Gather the set of unique labels.\n",
    "unique_labels = set()\n",
    "\n",
    "# Read the dataset line by line. Each line of the file\n",
    "# is either empty or has two tokens, separated by a tab.\n",
    "with open(\"./restauranttrain.bio\", newline = '') as lines:                                                                                          \n",
    "    \n",
    "    # Use the `csv` class to split the lines on the tab character.\n",
    "    line_reader = csv.reader(lines, delimiter='\\t')\n",
    "    \n",
    "    # For each line in the file...\n",
    "    for line in line_reader:\n",
    "        \n",
    "        # If we encounter a blank line, it means we've completed the previous \n",
    "        # sentence. \n",
    "        if line == []:\n",
    "\n",
    "            # Add the completed sentence.\n",
    "            sentences.append(tokens)\n",
    "            labels.append(token_labels)           \n",
    "    \n",
    "            # Start a new sentence.\n",
    "            tokens = []\n",
    "            token_labels = []        \n",
    "\n",
    "        else: \n",
    "            # Add the token and its label to the current sentence.\n",
    "            tokens.append(line[1])\n",
    "            token_labels.append(line[0])\n",
    "\n",
    "            # Add the label to the set (no effect if it already exists).\n",
    "            unique_labels.add(line[0])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyugAznPBNQ2"
   },
   "source": [
    "## Format IOB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHYaEItOcx9-"
   },
   "source": [
    "Voici les labels du jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b00POq7BchEn",
    "outputId": "cc7b4427-4c87-4353-8ee6-68492ec0e859"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-Amenity',\n",
       " 'B-Cuisine',\n",
       " 'B-Dish',\n",
       " 'B-Hours',\n",
       " 'B-Location',\n",
       " 'B-Price',\n",
       " 'B-Rating',\n",
       " 'B-Restaurant_Name',\n",
       " 'I-Amenity',\n",
       " 'I-Cuisine',\n",
       " 'I-Dish',\n",
       " 'I-Hours',\n",
       " 'I-Location',\n",
       " 'I-Price',\n",
       " 'I-Rating',\n",
       " 'I-Restaurant_Name',\n",
       " 'O'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7BbOt-rfdlQT"
   },
   "outputs": [],
   "source": [
    "# Map each unique label to an integer.\n",
    "label_map = {}\n",
    "\n",
    "# For each label...\n",
    "for (i, label) in enumerate(unique_labels):\n",
    "    \n",
    "    # Map it to its integer.\n",
    "    label_map[label] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtZahSM8_f4n",
    "outputId": "ed372a7f-8b66-47f7-eb45-0442b9c751de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 7,660\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training sentences: {:,}\".format(len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6iRs8gqD-8r5",
    "outputId": "d3caaf59-0276-41b0-ce32-881b6d180943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence:\n",
      "    Tokens: ['a', 'great', 'lunch', 'spot', 'but', 'open', 'till', '2', 'a', 'm', 'passims', 'kitchen']\n",
      "    Labels: ['O', 'O', 'O', 'O', 'O', 'B-Hours', 'I-Hours', 'I-Hours', 'I-Hours', 'I-Hours', 'B-Restaurant_Name', 'I-Restaurant_Name']\n",
      "\n",
      "Sentence Tokens and Labels:\n",
      "('a', 'O')\n",
      "('great', 'O')\n",
      "('lunch', 'O')\n",
      "('spot', 'O')\n",
      "('but', 'O')\n",
      "('open', 'B-Hours')\n",
      "('till', 'I-Hours')\n",
      "('2', 'I-Hours')\n",
      "('a', 'I-Hours')\n",
      "('m', 'I-Hours')\n",
      "('passims', 'B-Restaurant_Name')\n",
      "('kitchen', 'I-Restaurant_Name')\n"
     ]
    }
   ],
   "source": [
    "print(\"Example sentence:\")\n",
    "print (\"    Tokens:\", sentences[4])\n",
    "print (\"    Labels:\", labels[4])\n",
    "\n",
    "print ('\\nSentence Tokens and Labels:')\n",
    "for i in zip(sentences[4], labels[4]):\n",
    "  print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxxItg7vA5vc"
   },
   "source": [
    "Dictionnaire **label_map** qui aligne nos étiquettes (tags) à des entiers durant l'affinage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKZdvjwPDO9n",
    "outputId": "3e9f3904-ac29-4b9b-fa2d-bc3a3a353e21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-Location': 0,\n",
       " 'B-Price': 1,\n",
       " 'I-Restaurant_Name': 2,\n",
       " 'B-Dish': 3,\n",
       " 'B-Restaurant_Name': 4,\n",
       " 'I-Dish': 5,\n",
       " 'I-Amenity': 6,\n",
       " 'B-Hours': 7,\n",
       " 'I-Cuisine': 8,\n",
       " 'B-Cuisine': 9,\n",
       " 'I-Rating': 10,\n",
       " 'I-Price': 11,\n",
       " 'O': 12,\n",
       " 'I-Hours': 13,\n",
       " 'B-Amenity': 14,\n",
       " 'B-Rating': 15,\n",
       " 'B-Location': 16}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIDfAzc9C2wl"
   },
   "source": [
    "# 3. Segmentation et formatage de l'entrée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVA44wu4C5HL"
   },
   "source": [
    "Pour pouvoir utiliser BERT, on doit effectuer les actions suivantes:\n",
    "\n",
    "1. Les mots doivent être alignés avec leur ID dans le vocabulaire de BERT.\n",
    "2. Les mots qui ne font pas partie du vicabulaire sont sciendés en sous-mots.\n",
    "3. BERT impose l'ajout des jetons `[CLS]` au début de chaque phrase et `[SEP]` à la fin\n",
    "4. Les phrases doivent avoir la même longueur avec des jetons [PAD]` si nécessaire \n",
    "    * Cela nécessite l'ajout de masques d'attention qui permettent à BERT d'ignorer ces  jetons `[PAD]` \n",
    "\n",
    " Toutes ces actions sont possibles avec la fonction `encode_plus` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEyKypVX9-y6"
   },
   "source": [
    "## 3.1. Indiquer la longueur maximale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179,
     "referenced_widgets": [
      "f37d3625f4674ba1a5880cb948b3c515",
      "95619187e7df4635a69d16eecea70516",
      "5cf3f29eb9d84ccd9cf15ff9410cec42",
      "173538daa0124298aa51354244e618a0",
      "0608cf9867064dfdb6d47191267dcef3",
      "26931f1545114ec0acbd9ae48d34975b",
      "857a21a256164bed962c18412005f443",
      "99b50b2e93aa492084dae7323231d24b",
      "4782bd3d37644b86a1144c40c97415ed",
      "04536d1affa742018bfad17e882ac856",
      "4e4b86ea5ea446fab61e90bdc75a2907",
      "825e386629ad4dd58ed5ff8c911ae311",
      "3c21983880654de89855f381026d9e12",
      "26b9d1401cbe489e8c9adfcd5cd0a5a4",
      "1267d223e2f948a4be95c79f729bec93",
      "23d5c983fee049cd93c02ab4363da2a7",
      "4c635191b75f4a87b72ebf1ee2a4393b",
      "275c56dcde094dc19f5021f82ad183b6",
      "76555cfa5cec448cb4eb5e0af9cfd98a",
      "733111af075e4abab5ccff6ff349fb79",
      "4839be27939147f28d57dd1cf595cbf2",
      "ece437d972744a09a29b68ba551c260b",
      "422952d0392443eca3a52933966363e3",
      "31fe2a2e351a4ef7a033d07e5d025888",
      "dd910fdc8de24756a44c69a9de4b411d",
      "8c1049d6581141ebb9f1d90eea3bc39f",
      "67ee5ce9441441f7a2613c1f59ee979b",
      "1b215d808bde41de916d105f3e76d97f",
      "4ad9bf8f67d94d2bb46d820760597d2d",
      "7d648699af5d46d0b7cc8d4db397bcec",
      "b783329600d840769c100755256cb9a0",
      "56c8f08bc753473c81ae4481a643ef6c",
      "cb6991391ba94c0eb6ff83bc4ef83e8a",
      "325d29f21e444df2b92c65d9440d3558",
      "cf33bc631a5246ad9f58279b57dcd6a2",
      "b03d27744e444c2a9a227bc5aca6baef",
      "dff3f77cce8c4347aae5a934d47166ed",
      "d44ba7ac842b45b8bf04662ed54aa2f8",
      "399e8e3fb5d346ef9d1bb9628084e6ee",
      "3ec6e2c69ef849c0a95c9f6b8685b9ac",
      "59ffc9e12aff4e19a9d4329698b9aeee",
      "9b4a79871fa24247b89d0cda3bfe30ad",
      "c5d40eb29dc14338be4374ab85bdb9f3",
      "3e68b5a5741e4664882f859e4ae99130"
     ]
    },
    "id": "2bBdb3pt8LuQ",
    "outputId": "2c81caf1-b3a9-43e6-e834-f86f808379d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring sentence lengths...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "# We'll need the BertTokenizer in order to determine the number of tokens in\n",
    "# the sentences *according to BERT*.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Record the length of each sequence.\n",
    "lengths = []\n",
    "\n",
    "print('Measuring sentence lengths...')\n",
    "\n",
    "# For every sentence...\n",
    "for sen in sentences:\n",
    "\n",
    "    # Reconstruct the sentence to let BERT decide how to tokenize it.\n",
    "    sen = ' '.join(sen)\n",
    "\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sen,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Record the length of the sentence after tokenization.\n",
    "    lengths.append(len(encoded_sent))\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qmrQVSsjg6By",
    "outputId": "318cb1de-fae1-4ec6-dd87-f79ea5764af4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Min length: 3 tokens\n",
      "   Max length: 39 tokens\n",
      "Median length: 11 tokens\n"
     ]
    }
   ],
   "source": [
    "print('   Min length: {:,} tokens'.format(min(lengths)))\n",
    "print('   Max length: {:,} tokens'.format(max(lengths)))\n",
    "print('Median length: {:,} tokens'.format(int(np.median(lengths))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "iLhi9A49zmsy",
    "outputId": "42167ec7-ffae-42fd-b2de-a03e0d0cae5b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4180/1451923941.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'darkgrid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "\n",
    "# Plot the distribution of comment lengths.\n",
    "sns.distplot(lengths, kde=False, rug=False)\n",
    "\n",
    "plt.title('Sentence Lengths')\n",
    "plt.xlabel('Sentence Length')\n",
    "plt.ylabel('# of Sentences')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvs9RvI2dLNE"
   },
   "source": [
    "On peut voir qu'il y a des phrases très courtes. Comme on ne connait pas la longueur maximale de la phrase la plus longue du jeu de test, on la met à 50.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91PCHUVoEw3L"
   },
   "source": [
    "## 3.2. Nouvelle segmentation avec BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIWAoWL2RK1p"
   },
   "source": [
    "Nous utilisons la fonction `tokenizer.encode_plus` qui permet de:\n",
    "\n",
    "1. Scinder les mots inconnus en parties de mots (subwords).\n",
    "2. Ajouter les jetons spéciaux `[CLS]` et `[SEP]`.\n",
    "3. Aligner les jetons avec leurs IDs.\n",
    "4. Ajouter des Pad ou tronquer les phrases pour ne pas dépasser la longueur max.\n",
    "5. Créer les masques d'attention qui différencient les \"vrais\" jetons des `[PAD]` et qui permettent à BERT et à son mécanisme d'auto-attention d'ignorer les `[PAD]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rZLGEABFPez",
    "outputId": "dccf32f5-e878-448e-9d4d-a23eef8d3569"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soule\\.conda\\envs\\INF8460\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  ['2', 'start', 'restaurants', 'with', 'inside', 'dining']\n",
      "Token IDs: tensor([ 101, 1016, 2707, 7884, 2007, 2503, 7759,  102,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0])\n",
      "Masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "\n",
    "    # Reconstruct the sentence--otherwise `tokenizer` will interpret the list\n",
    "    # of string tokens as having already been tokenized by BERT.\n",
    "    sent_str = ' '.join(sent)\n",
    "\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent_str,                  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = 50,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'][0])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'][0])\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "print('Masks:', attention_masks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ze5ljJQuFkKL"
   },
   "source": [
    "## 3.3. Ajouter les labels Null "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRKfNEOuHQbM"
   },
   "source": [
    "La nouvelle segmentation a ajouté un ensemble de jetons (spéciaux, pad, segmentation des mots inconnus) et nos labels originaux ne sont donc plus alignés avec nos jetons. \n",
    "Nous allons donc ajouter un label null pour ces nouveaux jetons.\n",
    "\n",
    "Le dictionnaire aligne le jeton label à des IDs entiers unique. On en crée un nouveau d'ID `-100` pour les nouveaux jetons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "kDCfJPLjFn0r"
   },
   "outputs": [],
   "source": [
    "# New labels for all of the input sentences.\n",
    "new_labels = []\n",
    "\n",
    "# The special label ID we'll give to \"extra\" tokens.\n",
    "null_label_id = -100\n",
    "\n",
    "# For each sentence...\n",
    "for (sen, orig_labels) in zip(input_ids, labels):\n",
    "    \n",
    "    # Create a new list to hold the adjusted labels for this sentence.\n",
    "    padded_labels = []\n",
    "\n",
    "    # This will be our index into the original label list.\n",
    "    orig_labels_i = 0 \n",
    "\n",
    "    # For each token in the padded sentence...\n",
    "    for token_id in sen:\n",
    "\n",
    "        # Pull the value out of the tensor.\n",
    "        token_id = token_id.numpy().item()\n",
    "\n",
    "        # If `[PAD]`, `[CLS]`, or `[SEP]`...\n",
    "        if (token_id == tokenizer.pad_token_id) or \\\n",
    "            (token_id == tokenizer.cls_token_id) or \\\n",
    "            (token_id == tokenizer.sep_token_id):\n",
    "            \n",
    "            # Assign it the null label.\n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "        # If the token string starts with \"##\"...\n",
    "        elif tokenizer.ids_to_tokens[token_id][0:2] == '##':\n",
    "\n",
    "            # It's a subword token, and not part of the original dataset, so\n",
    "            # assign it the null label.\n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "        # If it's not any of the above...\n",
    "        else:\n",
    "            \n",
    "            # This token corresponds to one of the original ones, so assign it\n",
    "            # it's original label.\n",
    "\n",
    "            # Look up the label for this token.\n",
    "            label_str = orig_labels[orig_labels_i]\n",
    "\n",
    "            # Map the label to its ID, and assign it.\n",
    "            padded_labels.append(label_map[label_str])\n",
    "\n",
    "            # Increment our index into the original labels list.\n",
    "            orig_labels_i += 1\n",
    "\n",
    "    # If we did this right, then the new `padded_labels` list should match\n",
    "    # the length of the tokenized sentence.\n",
    "    assert(len(sen) == len(padded_labels))    \n",
    "\n",
    "    # Store the updated labels list for this sentence.\n",
    "    new_labels.append(padded_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uGVpkelQ4Hm"
   },
   "source": [
    "Exemple de phrase: \"5 star resturants in my town\" et son résultat après segmentation et remplacement des tokens :  Le premier sous-mot `rest` est associé au label original, tandis que  `##ura` et `##nts` ont pour label l'ID `-100`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k1xQC8xtRC_-",
    "outputId": "ec8cd9ac-de1b-4b99-c91c-4d567a264152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence:     ['5', 'star', 'resturants', 'in', 'my', 'town']\n",
      "\n",
      "Labels:       ['B-Rating', 'I-Rating', 'O', 'B-Location', 'I-Location', 'I-Location']\n",
      "\n",
      "BERT Tokens:  ['5', 'star', 'rest', '##ura', '##nts', 'in', 'my', 'town']\n",
      "\n",
      "Token IDs:    tensor([ 101, 1019, 2732, 2717, 4648, 7666, 1999, 2026, 2237,  102,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0])\n",
      "\n",
      "New Labels:   [-100, 15, 10, 12, -100, -100, 16, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "\n",
      "Mask:         tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n"
     ]
    }
   ],
   "source": [
    "print('\\nSentence:    ', sentences[2])\n",
    "print('\\nLabels:      ', labels[2])\n",
    "print('\\nBERT Tokens: ', tokenizer.tokenize(' '.join(sentences[2])))\n",
    "print('\\nToken IDs:   ', input_ids[2])\n",
    "print('\\nNew Labels:  ', new_labels[2])\n",
    "print('\\nMask:        ', attention_masks[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_npmX0BHRzk"
   },
   "source": [
    "On transforme nos listes Python en tenseurs Pytorch :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWOEAJQvPC6o"
   },
   "outputs": [],
   "source": [
    "# Convert the lists into PyTorch tensors.\n",
    "\n",
    "# `input_ids` is a list of tensor arrays--stack them into a matrix with size\n",
    "# [7,660  x  50].\n",
    "pt_input_ids = torch.stack(input_ids, dim=0)\n",
    "\n",
    "# `attention_masks` is a list of tensor arrays--stack them into a matrix with\n",
    "# size [7,660  x  50].\n",
    "pt_attention_masks = torch.stack(attention_masks, dim=0)\n",
    "\n",
    "# Labels is a list of lists. Convert it into a tensor matrix with size \n",
    "# [7,660  x  50].\n",
    "pt_labels = torch.tensor(new_labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yKfkY_ZUxxn"
   },
   "source": [
    "## 3.4. Entrainement et validation \n",
    "\n",
    "Division de l'ensemble d'entrainement en 90% train et 10% validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tk0MqIi7Uxxp",
    "outputId": "d51582c9-7e0e-4f64-b105-2f7b7202061c"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(pt_input_ids, pt_attention_masks, pt_labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYSos3lQUxxq"
   },
   "source": [
    "On utilise an iterator qui ne nécessite pas que tout l'ensemble de données soit en mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGUqOCtgqGhP"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bwa6Rts-02-"
   },
   "source": [
    "# 4. Entrainement du modèle de classification (affinage de BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6TKgyUzPIQc"
   },
   "source": [
    "## 4.1. BertForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAuiUrhCrNCB"
   },
   "source": [
    "BERT + un couche linéaire pour la classification de chaque jeton. Cette couche est ensuite  sur la tâche de classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QqgicdWMEPf2",
    "outputId": "dcdab43c-e12d-47b1-93f5-c78b0fa77111"
   },
   "outputs": [],
   "source": [
    "# This is the number of labels in our dataset, so we will be doing 18-way classification (all labels plus our padding label)\n",
    "len(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f10ef6ae6b3347f08e77318685612254",
      "3da688ac73294e74898a85eb06ae9614",
      "e73a303393dc4d5eb4eec24db31185ff",
      "77989b23f1dc47b0acda058d26cbb611",
      "2b11535aa53e49788d3ecaf074293af6",
      "5c4caa1f92ac44439ea6af2e47c3f992",
      "88464da4206a473190035e8fe919df8a",
      "3b7d123cb41f4d3ba3de978ca8393659",
      "2e3706c686eb4db0a4559075503dab94",
      "fcf1a675dba74df78d19e184ccfac2fc",
      "c1aa7e6bb74b4d50a09fa80bbec53dbc"
     ]
    },
    "id": "gFsCTp_mporB",
    "outputId": "925aaba5-8c27-40fe-b98a-cee9604b59e4"
   },
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForTokenClassification \n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = len(label_map) + 1, # The number of output labels--18 for our NER dataset\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRWT-D4U_Pvx"
   },
   "source": [
    "## 4.2. Optimizer / Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLs72DuMODJO"
   },
   "outputs": [],
   "source": [
    "# Load the AdamW optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # args.learning_rate \n",
    "                  eps = 1e-8 # args.adam_epsilon \n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-p0upAhhRiIx"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs \n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqfmWwUR_Sox"
   },
   "source": [
    "## 4.3. Boucle d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpt6tR83keZD"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6J-FYdx6nFE_",
    "outputId": "38d6eb38-e763-4f16-fc7c-f87630952c93"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertfortokenclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.TokenClassifierOutput\n",
    "        result = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        loss = result.loss\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-G03mmwH3aI"
   },
   "source": [
    "On étudie notre perte sur l'ensemble d'entrainement sur tous les \"batches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "zBhywMlXVmUJ",
    "outputId": "b50a7b77-dccf-4dd3-8b27-8e995f4f57e4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkyubuJSOzg3"
   },
   "source": [
    "# 5. Performance sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30w5nU1aY4Pp"
   },
   "source": [
    "### 5.1. Préparation des données\n",
    "\n",
    "Mêmes étapes que pour les données d'entrainement pour l'ensemble de test \"./restauranttest.bio\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mF3N0K9SY-OJ"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# List of all sentences in the dataset.\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "# Lists to store the current sentence.\n",
    "tokens = []\n",
    "token_labels = []\n",
    "\n",
    "# Gather the set of unique labels.\n",
    "unique_labels = set()\n",
    "\n",
    "# Read the dataset line by line. Each line of the file\n",
    "# is either empty or has two tokens, separated by a tab.\n",
    "with open(\"./restauranttest.bio\", newline = '') as lines:                                                                                          \n",
    "    \n",
    "    # Use the `csv` class to split the lines on the tab character.\n",
    "    line_reader = csv.reader(lines, delimiter='\\t')\n",
    "    \n",
    "    # For each line in the file...\n",
    "    for line in line_reader:\n",
    "        \n",
    "        # If we encounter a blank line, it means we've completed the previous \n",
    "        # sentence. \n",
    "        if line == []:\n",
    "\n",
    "            # Add the completed sentence.\n",
    "            sentences.append(tokens)\n",
    "            labels.append(token_labels)           \n",
    "    \n",
    "            # Start a new sentence.\n",
    "            tokens = []\n",
    "            token_labels = []        \n",
    "\n",
    "        else: \n",
    "            # Add the token and its label to the current sentence.\n",
    "            tokens.append(line[1])\n",
    "            token_labels.append(line[0])\n",
    "\n",
    "            # Add the label to the set (no effect if it already exists).\n",
    "            unique_labels.add(line[0])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7_Vsn6tZQJq"
   },
   "source": [
    "**Segmentation avec BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JFQ-vencZQJt",
    "outputId": "dcd151e9-45a1-4f6f-ed9a-80ca85b39f29"
   },
   "outputs": [],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "\n",
    "    # Reconstruct the sentence--otherwise `tokenizer` will interpret the list\n",
    "    # of string tokens as having already been tokenized by BERT.\n",
    "    sent_str = ' '.join(sent)\n",
    "\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent_str,                  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 50,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'][0])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'][0])\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "print('Masks:', attention_masks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ACse-8LZQJv"
   },
   "source": [
    "**Labels Null**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPPjb6t_ZQJw"
   },
   "outputs": [],
   "source": [
    "# New labels for all of the input sentences.\n",
    "new_labels = []\n",
    "\n",
    "# The special label ID we'll give to \"extra\" tokens.\n",
    "null_label_id = -100\n",
    "\n",
    "# For each sentence...\n",
    "for (sen, orig_labels) in zip(input_ids, labels):\n",
    "    \n",
    "    # Create a new list to hold the adjusted labels for this sentence.\n",
    "    padded_labels = []\n",
    "\n",
    "    # This will be our index into the original label list.\n",
    "    orig_labels_i = 0 \n",
    "\n",
    "    # For each token in the padded sentence...\n",
    "    for token_id in sen:\n",
    "        \n",
    "        # Pull the value out of the tensor.\n",
    "        token_id = token_id.numpy().item()\n",
    "\n",
    "        # If `[PAD]`, `[CLS]`, or `[SEP]`...\n",
    "        if (token_id == tokenizer.pad_token_id) or \\\n",
    "            (token_id == tokenizer.cls_token_id) or \\\n",
    "            (token_id == tokenizer.sep_token_id):\n",
    "            \n",
    "            # Assign it the null label.\n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "        # If the token string starts with \"##\"...\n",
    "        elif tokenizer.ids_to_tokens[token_id][0:2] == '##':\n",
    "\n",
    "            # It's a subword token, and not part of the original dataset, so\n",
    "            # assign it the null label.\n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "        # If it's not any of the above...\n",
    "        else:\n",
    "            \n",
    "            # This token corresponds to one of the original ones, so assign it\n",
    "            # it's original label.\n",
    "\n",
    "            # Look up the label for this token.\n",
    "            label_str = orig_labels[orig_labels_i]\n",
    "\n",
    "            # Map the label to its ID, and assign it.\n",
    "            padded_labels.append(label_map[label_str])\n",
    "\n",
    "            # Increment our index into the original labels list.\n",
    "            orig_labels_i += 1\n",
    "\n",
    "    # If we did this right, then the new `padded_labels` list should match\n",
    "    # the length of the tokenized sentence.\n",
    "    assert(len(sen) == len(padded_labels))    \n",
    "\n",
    "    # Store the updated labels list for this sentence.\n",
    "    new_labels.append(padded_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6R8-GMHXZQJz",
    "outputId": "370c34dc-86ef-4de6-a4ff-bc992d84955d"
   },
   "outputs": [],
   "source": [
    "print('\\nSentence:    ', sentences[2])\n",
    "print('\\nLabels:      ', labels[2])\n",
    "print('\\nBERT Tokens: ', tokenizer.tokenize(' '.join(sentences[2])))\n",
    "print('\\nToken IDs:   ', input_ids[2])\n",
    "print('\\nMask:        ', attention_masks[2])\n",
    "print('\\nNew Labels:  ', new_labels[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYs1JgJfbzqr"
   },
   "source": [
    "**DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PV_qRH48ZQJ1"
   },
   "outputs": [],
   "source": [
    "# Convert the lists into PyTorch tensors.\n",
    "\n",
    "# `input_ids` is a list of tensor arrays--stack them into a matrix.\n",
    "pt_input_ids = torch.stack(input_ids, dim=0)\n",
    "\n",
    "# `attention_masks` is a list of tensor arrays--stack them into a matrix.\n",
    "pt_attention_masks = torch.stack(attention_masks, dim=0)\n",
    "\n",
    "# Labels is a list of lists. Convert it into a tensor matrix.\n",
    "pt_labels = torch.tensor(new_labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEEOBcMKY4Ps"
   },
   "outputs": [],
   "source": [
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(pt_input_ids, pt_attention_masks, pt_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16lctEOyNFik"
   },
   "source": [
    "## 5.2. Evaluation sur l'ensemble de test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhR99IISNMg9"
   },
   "source": [
    "On peut utiliser notre modèle affiné pour générer des prédictions sur l'ensemble de test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hba10sXR7Xi6",
    "outputId": "9eddf920-d6f2-4902-eadd-df29bf55bdde"
   },
   "outputs": [],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(pt_input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      result = model(b_input_ids, \n",
    "                      token_type_ids=None, \n",
    "                      attention_mask=b_input_mask,\n",
    "                      return_dict=True)\n",
    "\n",
    "  logits = result.logits\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdkfN3GFDz2b"
   },
   "source": [
    "On va maintenant évaluer ces prédictions avec la métrique f1_score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wM_KID9aIZj6",
    "outputId": "4476a162-dea0-4fb8-a0ee-1c5710304bf7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# First, combine the results across the batches.\n",
    "all_predictions = np.concatenate(predictions, axis=0)\n",
    "all_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "print(\"After flattening the batches, the predictions have shape:\")\n",
    "print(\"    \", all_predictions.shape)\n",
    "\n",
    "# Next, let's remove the third dimension (axis 2), which has the scores\n",
    "# for all 18 labels. \n",
    "\n",
    "# For each token, pick the label with the highest score.\n",
    "predicted_label_ids = np.argmax(all_predictions, axis=2)\n",
    "\n",
    "print(\"\\nAfter choosing the highest scoring label for each token:\")\n",
    "print(\"    \", predicted_label_ids.shape) \n",
    "\n",
    "# Finally, for the sake of scoring, we don't actually care about the different\n",
    "# sentences--we just look at whether the model made correct predictions for the\n",
    "# individual tokens.\n",
    "\n",
    "# Eliminate axis 0, which corresponds to the sentences.\n",
    "predicted_label_ids = np.concatenate(predicted_label_ids, axis=0)\n",
    "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
    "\n",
    "print(\"\\nAfter flattening the sentences, we have predictions:\")\n",
    "print(\"    \", predicted_label_ids.shape)\n",
    "print(\"and ground truth:\")\n",
    "print(\"    \", all_true_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oCLbJXOQFhE"
   },
   "source": [
    "Avant d'évaluer, on enlèle les tokens étiquetés avec `null`\n",
    "Dans un vrai système de NER : on ignorerait aussi les prédictions pour les jetons `[CLS]`, `[SEP]`, et `[PAD]` et on utiliserait la prédiction du premier sous-mot pour toutes les parties du mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8ve17VPQE4z",
    "outputId": "8079fa0f-2b4f-4847-b066-8b15dafab635"
   },
   "outputs": [],
   "source": [
    "# Construct new lists of predictions which don't include any null tokens.\n",
    "real_token_predictions = []\n",
    "real_token_labels = []\n",
    "\n",
    "# For each of the input tokens in the dataset...\n",
    "for i in range(len(all_true_labels)):\n",
    "\n",
    "    # If it's not a token with a null label...\n",
    "    if not all_true_labels[i] == -100:\n",
    "        \n",
    "        # Add the prediction and the ground truth to their lists.\n",
    "        real_token_predictions.append(predicted_label_ids[i])\n",
    "        real_token_labels.append(all_true_labels[i])\n",
    "\n",
    "print(\"Before filtering out `null` tokens, length = {:,}\".format(len(all_true_labels)))\n",
    "print(\" After filtering out `null` tokens, length = {:,}\".format(len(real_token_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1q7ggFNaTkWu",
    "outputId": "588aaa49-4fbb-4c4d-828a-85bac8ebccf8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate the F1 score. Because this is a multi-class problem, we have\n",
    "# to set the `average` parameter. TODO - What does `micro` do?\n",
    "f1 = f1_score(real_token_labels, real_token_predictions, average='micro') \n",
    "\n",
    "print (\"F1 score: {:.2%}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2079Qyn8Mt8"
   },
   "source": [
    "##  Sauvegarder et charger un modèle affiné "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ulTWaOr8QNY",
    "outputId": "6185dc6a-75c0-4e1d-f446-60c63fecbbfa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = './model_save/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Good practice: save your training arguments together with the trained model\n",
    "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mqMzI3VTCZo5",
    "outputId": "63864d7d-404b-4f0d-dfb1-ea0689a8fdbc"
   },
   "outputs": [],
   "source": [
    "!ls -l --block-size=K ./model_save/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fr_bt2rFlgDn"
   },
   "source": [
    "Le fichier le plus large consiste en les poids du modèl (418 megaoctets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WUFUIQ8Cu8D",
    "outputId": "80cb742f-51e9-4f6c-e14d-23f4359c1fbc"
   },
   "outputs": [],
   "source": [
    "!ls -l --block-size=M ./model_save/pytorch_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Trr-A-POC18_"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive to this Notebook instance.\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxlZsafTC-V5"
   },
   "outputs": [],
   "source": [
    "# Copy the model files to a directory in your Google Drive.\n",
    "!cp -r ./model_save/ \"./drive/BERT Fine-Tuning/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0vstijw85SZ"
   },
   "source": [
    "Chargement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nskPzUM084zL"
   },
   "outputs": [],
   "source": [
    "# Load a trained model and vocabulary that you have fine-tuned\n",
    "model = model_class.from_pretrained(output_dir)\n",
    "tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
    "\n",
    "# Copy the model to the GPU.\n",
    "model.to(device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "inf8460_cours10_BERT_Fine_Tuning_NER.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04536d1affa742018bfad17e882ac856": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0608cf9867064dfdb6d47191267dcef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e4b86ea5ea446fab61e90bdc75a2907",
      "placeholder": "​",
      "style": "IPY_MODEL_04536d1affa742018bfad17e882ac856",
      "value": " 226k/226k [00:00&lt;00:00, 574kB/s]"
     }
    },
    "1267d223e2f948a4be95c79f729bec93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_733111af075e4abab5ccff6ff349fb79",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_76555cfa5cec448cb4eb5e0af9cfd98a",
      "value": 28
     }
    },
    "173538daa0124298aa51354244e618a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4782bd3d37644b86a1144c40c97415ed",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_99b50b2e93aa492084dae7323231d24b",
      "value": 231508
     }
    },
    "1b215d808bde41de916d105f3e76d97f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23d5c983fee049cd93c02ab4363da2a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ece437d972744a09a29b68ba551c260b",
      "placeholder": "​",
      "style": "IPY_MODEL_4839be27939147f28d57dd1cf595cbf2",
      "value": " 28.0/28.0 [00:00&lt;00:00, 456B/s]"
     }
    },
    "26931f1545114ec0acbd9ae48d34975b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26b9d1401cbe489e8c9adfcd5cd0a5a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_275c56dcde094dc19f5021f82ad183b6",
      "placeholder": "​",
      "style": "IPY_MODEL_4c635191b75f4a87b72ebf1ee2a4393b",
      "value": "Downloading: 100%"
     }
    },
    "275c56dcde094dc19f5021f82ad183b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b11535aa53e49788d3ecaf074293af6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1aa7e6bb74b4d50a09fa80bbec53dbc",
      "placeholder": "​",
      "style": "IPY_MODEL_fcf1a675dba74df78d19e184ccfac2fc",
      "value": " 420M/420M [00:15&lt;00:00, 29.8MB/s]"
     }
    },
    "2e3706c686eb4db0a4559075503dab94": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31fe2a2e351a4ef7a033d07e5d025888": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "325d29f21e444df2b92c65d9440d3558": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b03d27744e444c2a9a227bc5aca6baef",
       "IPY_MODEL_dff3f77cce8c4347aae5a934d47166ed",
       "IPY_MODEL_d44ba7ac842b45b8bf04662ed54aa2f8"
      ],
      "layout": "IPY_MODEL_cf33bc631a5246ad9f58279b57dcd6a2"
     }
    },
    "399e8e3fb5d346ef9d1bb9628084e6ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b7d123cb41f4d3ba3de978ca8393659": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3c21983880654de89855f381026d9e12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3da688ac73294e74898a85eb06ae9614": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e68b5a5741e4664882f859e4ae99130": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ec6e2c69ef849c0a95c9f6b8685b9ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "422952d0392443eca3a52933966363e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dd910fdc8de24756a44c69a9de4b411d",
       "IPY_MODEL_8c1049d6581141ebb9f1d90eea3bc39f",
       "IPY_MODEL_67ee5ce9441441f7a2613c1f59ee979b"
      ],
      "layout": "IPY_MODEL_31fe2a2e351a4ef7a033d07e5d025888"
     }
    },
    "4782bd3d37644b86a1144c40c97415ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4839be27939147f28d57dd1cf595cbf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ad9bf8f67d94d2bb46d820760597d2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c635191b75f4a87b72ebf1ee2a4393b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4e4b86ea5ea446fab61e90bdc75a2907": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56c8f08bc753473c81ae4481a643ef6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59ffc9e12aff4e19a9d4329698b9aeee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5c4caa1f92ac44439ea6af2e47c3f992": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5cf3f29eb9d84ccd9cf15ff9410cec42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_857a21a256164bed962c18412005f443",
      "placeholder": "​",
      "style": "IPY_MODEL_26931f1545114ec0acbd9ae48d34975b",
      "value": "Downloading: 100%"
     }
    },
    "67ee5ce9441441f7a2613c1f59ee979b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb6991391ba94c0eb6ff83bc4ef83e8a",
      "placeholder": "​",
      "style": "IPY_MODEL_56c8f08bc753473c81ae4481a643ef6c",
      "value": " 455k/455k [00:00&lt;00:00, 631kB/s]"
     }
    },
    "733111af075e4abab5ccff6ff349fb79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76555cfa5cec448cb4eb5e0af9cfd98a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "77989b23f1dc47b0acda058d26cbb611": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e3706c686eb4db0a4559075503dab94",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3b7d123cb41f4d3ba3de978ca8393659",
      "value": 440473133
     }
    },
    "7d648699af5d46d0b7cc8d4db397bcec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "825e386629ad4dd58ed5ff8c911ae311": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_26b9d1401cbe489e8c9adfcd5cd0a5a4",
       "IPY_MODEL_1267d223e2f948a4be95c79f729bec93",
       "IPY_MODEL_23d5c983fee049cd93c02ab4363da2a7"
      ],
      "layout": "IPY_MODEL_3c21983880654de89855f381026d9e12"
     }
    },
    "857a21a256164bed962c18412005f443": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88464da4206a473190035e8fe919df8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c1049d6581141ebb9f1d90eea3bc39f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b783329600d840769c100755256cb9a0",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7d648699af5d46d0b7cc8d4db397bcec",
      "value": 466062
     }
    },
    "95619187e7df4635a69d16eecea70516": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99b50b2e93aa492084dae7323231d24b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9b4a79871fa24247b89d0cda3bfe30ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b03d27744e444c2a9a227bc5aca6baef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ec6e2c69ef849c0a95c9f6b8685b9ac",
      "placeholder": "​",
      "style": "IPY_MODEL_399e8e3fb5d346ef9d1bb9628084e6ee",
      "value": "Downloading: 100%"
     }
    },
    "b783329600d840769c100755256cb9a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1aa7e6bb74b4d50a09fa80bbec53dbc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5d40eb29dc14338be4374ab85bdb9f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cb6991391ba94c0eb6ff83bc4ef83e8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf33bc631a5246ad9f58279b57dcd6a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d44ba7ac842b45b8bf04662ed54aa2f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e68b5a5741e4664882f859e4ae99130",
      "placeholder": "​",
      "style": "IPY_MODEL_c5d40eb29dc14338be4374ab85bdb9f3",
      "value": " 570/570 [00:00&lt;00:00, 12.3kB/s]"
     }
    },
    "dd910fdc8de24756a44c69a9de4b411d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ad9bf8f67d94d2bb46d820760597d2d",
      "placeholder": "​",
      "style": "IPY_MODEL_1b215d808bde41de916d105f3e76d97f",
      "value": "Downloading: 100%"
     }
    },
    "dff3f77cce8c4347aae5a934d47166ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b4a79871fa24247b89d0cda3bfe30ad",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_59ffc9e12aff4e19a9d4329698b9aeee",
      "value": 570
     }
    },
    "e73a303393dc4d5eb4eec24db31185ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88464da4206a473190035e8fe919df8a",
      "placeholder": "​",
      "style": "IPY_MODEL_5c4caa1f92ac44439ea6af2e47c3f992",
      "value": "Downloading: 100%"
     }
    },
    "ece437d972744a09a29b68ba551c260b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f10ef6ae6b3347f08e77318685612254": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e73a303393dc4d5eb4eec24db31185ff",
       "IPY_MODEL_77989b23f1dc47b0acda058d26cbb611",
       "IPY_MODEL_2b11535aa53e49788d3ecaf074293af6"
      ],
      "layout": "IPY_MODEL_3da688ac73294e74898a85eb06ae9614"
     }
    },
    "f37d3625f4674ba1a5880cb948b3c515": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5cf3f29eb9d84ccd9cf15ff9410cec42",
       "IPY_MODEL_173538daa0124298aa51354244e618a0",
       "IPY_MODEL_0608cf9867064dfdb6d47191267dcef3"
      ],
      "layout": "IPY_MODEL_95619187e7df4635a69d16eecea70516"
     }
    },
    "fcf1a675dba74df78d19e184ccfac2fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
